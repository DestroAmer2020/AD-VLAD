{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k_GncttFw0b"
      },
      "source": [
        "# **Лабораторна робота 3**\n",
        "\n",
        "Для виконання цієї лабораторної робити Вам необхідно використати набори даних, що ви створили в **Лабораторній роботі 2**.\n",
        "\n",
        "**Всі завдання виконуються індивідуально. Використання запозиченого коду буде оцінюватись в 0 балів.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D-HOiM_-ZCw"
      },
      "source": [
        "**Завдання 1.** Ви маєте набір даних, який складається з двох лінійно роздільних класів. Вам необхідно застосувати під цей набір даних мінімум **3  моледі машинного навчання** для класифікації цих даних та оцінити їх продуктивність.\n",
        "\n",
        "**Пояснення до завдання 1:**\n",
        "\n",
        "- обрати 3 моделі для класифікації даних та навчити їх;\n",
        "- оцінити їх продуктивність за допомогою трьох метрик точності;\n",
        "- візуалізувати розподіл даних та межі класифікації кожної моделі;\n",
        "- провести аналіз отриманих результатів, виявляючи, яка модель найкраще підходить для цього набору даних та чому."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbFTHCQe9lTJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_classification(n_samples=100, n_features=2, n_classes=2, n_clusters_per_class=1, n_informative=2, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsOFU24BAOVh"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"SVM\": SVC(kernel='linear'),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=3)\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZWvPq6qAONU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "metrics = {\n",
        "    \"Accuracy\": accuracy_score,\n",
        "    \"Precision\": precision_score,\n",
        "    \"Recall\": recall_score\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    results[model_name] = {metric_name: metric(y_test, y_pred) for metric_name, metric in metrics.items()}\n",
        "\n",
        "for model_name, model_metrics in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"{metric_name}: {value:.2f}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH97WM3pAOEo"
      },
      "outputs": [],
      "source": [
        "for model_name, model in models.items():\n",
        "    plt.figure()\n",
        "    h = .02\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n",
        "    plt.title(f\"Classification boundary of {model_name}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSw6McHxAPpc"
      },
      "source": [
        "**Аналіз отриманих результатів**:\n",
        "\n",
        "1. Логістична регресія:\n",
        "* Accuracy: 0.93\n",
        "* Precision: 0.92\n",
        "* Recall: 0.90\n",
        "- Високі показники точності (accuracy) та precision свідчать про те, що модель правильно * класифікує більшість даних. Recall трохи нижчий, що може означати, що модель не завжди виявляє всі позитивні класи.\n",
        "\n",
        "2. SVM:\n",
        "* Accuracy: 0.95\n",
        "* Precision: 0.94\n",
        "* Recall: 0.93\n",
        "- Результат показав найкращі результати серед усіх моделей. Висока точність (accuracy) та метрики precision і recall вказують на те, що модель чітко відокремлює класи, знаходячи оптимальну гіперплощину між ними. SVM є оптимальним вибором для лінійно роздільних класів.\n",
        "\n",
        "3. KNN:\n",
        "* Accuracy: 0.85\n",
        "* Precision: 0.83\n",
        "* Recall: 0.82\n",
        "- KNN показав дещо нижчі результати порівняно з іншими моделями. Це може бути пов'язано з тим, що KNN не є лінійною моделлю і може не впоратися з лінійно роздільними даними так добре, як лінійні методи (логістична регресія та SVM). Проте цей алгоритм залишається корисним у випадках, коли дані мають нелінійну структуру або більш складні класи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_jATNGCA01l"
      },
      "source": [
        "**Завдання 2.** Ви маєте набір даних, що містить три класи, які частково перетинаються. Вам необхідно застосувати під цей набір даних мінімум **3  моледі машинного навчання** для класифікації цих даних та оцінити їх продуктивність.\n",
        "\n",
        "**Пояснення до завдання 2:**\n",
        "\n",
        "- обрати 3 моделі для класифікації даних та навчити їх;\n",
        "- оцінити їх продуктивність за допомогою трьох метрик точності;\n",
        "- провести візуалізацію результатів класифікації, підкреслюючи області, де моделі помиляються.\n",
        "- подумайте та опишіть у висновках, як перекриття між класами впливає на продуктивність моделей і які методи найкраще справляються з цими даними.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RwMmg-wAo2r"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_classification(n_samples=200, n_features=2, n_classes=3, n_clusters_per_class=1, n_informative=2, n_redundant=0, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTiq_-NqBn-1"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(multi_class='ovr', max_iter=1000),\n",
        "    \"SVM\": SVC(kernel='linear', decision_function_shape='ovr'),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc0STKi4Bn4R"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "metrics = {\n",
        "    \"Accuracy\": accuracy_score,\n",
        "    \"Precision (macro)\": lambda y_true, y_pred: precision_score(y_true, y_pred, average='macro'),\n",
        "    \"Recall (macro)\": lambda y_true, y_pred: recall_score(y_true, y_pred, average='macro')\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    results[model_name] = {metric_name: metric(y_test, y_pred) for metric_name, metric in metrics.items()}\n",
        "\n",
        "for model_name, model_metrics in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"{metric_name}: {value:.2f}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLQ_dN9mBnwT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    plt.figure()\n",
        "    h = .02 \n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n",
        "    plt.title(f\"Classification boundary of {model_name}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12CGT7aBBteY"
      },
      "source": [
        "**Аналіз отриманих результатів**:\n",
        "\n",
        "1. Логістична регресія:\n",
        "* Продуктивність: Модель може працювати досить добре на частково перетинаючихся класах, проте межі будуть лінійними, що може не враховувати всю складність перетину між класами.\n",
        "* Помилки: Області помилок будуть в місцях, де класи мають найбільше перекриття.\n",
        "* Висновок: Логістична регресія має лімітовану здатність працювати з більш складними даними через лінійність меж.\n",
        "\n",
        "2. SVM:\n",
        "* Продуктивність: SVM, використовуючи лінійне ядро, також може зіткнутися з труднощами через лінійність. Проте, якщо використати нелінійне ядро (наприклад, радіальне), SVM може краще впоратися з перекриттями.\n",
        "* Помилки: SVM може краще визначати оптимальні межі між класами з перекриттями, але з лінійним ядром також матиме труднощі.\n",
        "* Висновок: Нелінійні ядра можуть покращити продуктивність.\n",
        "\n",
        "3. K-ближчих сусідів (KNN):\n",
        "* Продуктивність: KNN краще справляється з даними, де класи частково перетинаються, оскільки модель враховує локальну структуру даних. Проте продуктивність залежить від вибору кількості сусідів.\n",
        "* Помилки: Помилки можливі в областях, де близькі точки належать до різних класів.\n",
        "* Висновок: KNN підходить для роботи з даними, що мають складніші межі між класами.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ad2fOD6CLWj"
      },
      "source": [
        "**Завдання 3.** Ви маєте набір даних, де один тор оточений іншим, утворюючи складну топологію. Вам необхідно застосувати під цей набір даних мінімум **3  моледі машинного навчання** для класифікації цих даних та оцінити їх продуктивність.\n",
        "\n",
        "**Пояснення до завдання 3:**\n",
        "\n",
        "- обрати 3 моделі для класифікації даних та навчити їх;\n",
        "- оцінити їх продуктивність за допомогою трьох метрик точності;\n",
        "- побудувати візуалізацію результатів класифікації;\n",
        "- проаналізувати, яка модель найкраще адаптується до складної топології даних і чому."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1fwddAMBxEK"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_circles(n_samples=500, factor=0.5, noise=0.1, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ7zfI6ZC457"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "models = {\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"SVM (RBF kernel)\": SVC(kernel='rbf'),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80OZX6OVC4wt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "metrics = {\n",
        "    \"Accuracy\": accuracy_score,\n",
        "    \"Precision\": precision_score,\n",
        "    \"Recall\": recall_score\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    results[model_name] = {metric_name: metric(y_test, y_pred) for metric_name, metric in metrics.items()}\n",
        "\n",
        "for model_name, model_metrics in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"{metric_name}: {value:.2f}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0XnJaU9C4o6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    plt.figure()\n",
        "    h = .02 \n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n",
        "    plt.title(f\"Classification boundary of {model_name}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egcENYqYC-AR"
      },
      "source": [
        "**Аналіз отриманих результатів**:\n",
        "\n",
        "1. KNN:\n",
        "* Продуктивність: KNN добре підходить для таких даних, оскільки враховує локальні характеристики даних. Проте модель може бути чутливою до вибору кількості сусідів.\n",
        "* Помилки: Помилки можуть бути в місцях, де точки з різних класів розташовані близько один до одного.\n",
        "* Висновок: KNN показує хорошу адаптивність до даних зі складною топологією.\n",
        "\n",
        "2. SVM з нелінійним ядром (RBF kernel):\n",
        "* Продуктивність: Нелінійне ядро RBF дозволяє SVM ефективно працювати на даних з нелінійними межами класифікації.\n",
        "* Помилки: SVM може краще впоратися з визначенням меж між класами, ніж KNN, особливо в місцях перетину.\n",
        "* Висновок: SVM з RBF ядром є дуже ефективним для таких даних завдяки можливості моделювати складні межі.\n",
        "\n",
        "3. Random Forest:\n",
        "* Продуктивність: Random Forest може адаптуватися до складної топології даних завдяки використанню ансамблю дерев рішень.\n",
        "* Помилки: Модель може зробити помилки в більш чутливих до топології частинах даних, але в цілому показує стабільні результати.\n",
        "* Висновок: Random Forest демонструє хорошу продуктивність і стабільні результати для складних топологій."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSSTyYMDKUm"
      },
      "source": [
        "**Завдання 4.** Ви маєте набір даних, що складається з двох класів, які утворюють подвійну спіраль. Вам необхідно застосувати під цей набір даних мінімум **3  моледі машинного навчання** для класифікації цих даних та оцінити їх продуктивність.\n",
        "\n",
        "**Пояснення до завдання 4:**\n",
        "\n",
        "- обрати 3 моделі для класифікації даних та навчити їх;\n",
        "- оцінити їх продуктивність за допомогою трьох метрик точності;\n",
        "- візуалізувати дані та межі класифікації кожної моделі для оцінки їх ефективності.\n",
        "- подумайте та напишіть у висновках, яка модель найкраще підходить для цього типу даних і як нелінійність впливає на процес класифікації."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDJDM9ptFiTI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def create_spiral_dataset(n_points, noise=0.5):\n",
        "    n = np.sqrt(np.random.rand(n_points,1)) * 780 * (2*np.pi)/360\n",
        "    d1x = -np.cos(n)*n + np.random.rand(n_points,1) * noise\n",
        "    d1y = np.sin(n)*n + np.random.rand(n_points,1) * noise\n",
        "    X = np.vstack((np.hstack((d1x,d1y)), np.hstack((-d1x,-d1y))))\n",
        "    y = np.hstack((np.zeros(n_points), np.ones(n_points)))\n",
        "    return X, y\n",
        "\n",
        "X, y = create_spiral_dataset(500, noise=0.1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtkIx0V1FiK5"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "models = {\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"SVM (RBF kernel)\": SVC(kernel='rbf'),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRkscmFqFiDl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "metrics = {\n",
        "    \"Accuracy\": accuracy_score,\n",
        "    \"Precision\": precision_score,\n",
        "    \"Recall\": recall_score\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    results[model_name] = {metric_name: metric(y_test, y_pred) for metric_name, metric in metrics.items()}\n",
        "\n",
        "for model_name, model_metrics in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    for metric_name, value in model_metrics.items():\n",
        "        print(f\"{metric_name}: {value:.2f}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGO_nEB8Fh6l"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    plt.figure()\n",
        "    h = .02 \n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o')\n",
        "    plt.title(f\"Classification boundary of {model_name}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAzIXURHFpOs"
      },
      "source": [
        "**Аналіз отриманих результатів**:\n",
        "\n",
        "1. KNN:\n",
        "* Продуктивність: KNN здатний враховувати локальні особливості даних, але може не так добре працювати на складних топологіях, як подвійна спіраль, якщо вибрати невдале значення параметра n_neighbors.\n",
        "* Помилки: Помилки можуть виникати в точках, де класові межі сильно сплітаються.\n",
        "* Висновок: KNN демонструє стабільні результати, проте на такому складному наборі даних може бути недостатньо ефективним.\n",
        "\n",
        "2. SVM з нелінійним ядром (RBF kernel):\n",
        "* Продуктивність: SVM з RBF ядром здатен моделювати нелінійні межі між класами. Для подвійної спіралі ця модель може бути однією з найкращих завдяки її здатності враховувати складні межі.\n",
        "* Помилки: Помилки можуть виникати на найскладніших для розділення ділянках.\n",
        "* Висновок: SVM з RBF ядром є найкращим варіантом для таких нелінійних даних.\n",
        "\n",
        "3. Random Forest:\n",
        "* Продуктивність: Random Forest має хорошу здатність адаптуватися до складних меж між класами завдяки своїй ансамблевій природі. Проте на таких специфічних нелінійних даних може поступитися SVM.\n",
        "* Помилки: Модель може мати труднощі в точках, де класи дуже тісно переплітаються.\n",
        "* Висновок: Random Forest демонструє хороші результати, але складна нелінійність спіралі може вимагати більш специфічних моделей."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
