{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSxjj4vVNqyC"
      },
      "source": [
        "# **Лабораторна робота 4: Прогнозування даних системи Лоренца та об'єктів Нарендра-Пархтізаратхі за допомогою  моделей машинного навчання**\n",
        "**Всі завдання виконуються індивідуально. Використання запозиченого коду буде оцінюватись в 0 балів.**\n",
        "\n",
        "**Лабораторні роботи де в коді буде використаня КИРИЛИЦІ будуть оцінюватись в 20 балів.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQMfGkiCHsqr"
      },
      "source": [
        "#### **Мета роботи:**\n",
        "\n",
        " Робота з даними, згенерованими системою Лоренца та об'єктами Нарендра-Пархтізаратхі, для передбачення майбутніх значеннь за допомогою  моделей машинного навчання.\n",
        "\n",
        "#### **Система Лоренца:**\n",
        "\n",
        "Система Лоренца описується трьома диференціальними рівняннями:\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "\\frac{dx}{dt} = \\sigma (y - x) \\\\\n",
        "\\frac{dy}{dt} = x (\\rho - z) - y \\\\\n",
        "\\frac{dz}{dt} = xy - \\beta z\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "де:\n",
        "- $( \\sigma )$ — коефіцієнт Прандтля (зазвичай $ \\sigma = 10 $),\n",
        "- $( \\rho )$ — числовий параметр для турбулентності (зазвичай $ \\rho = 28 $),\n",
        "- $( \\beta )$ — коефіцієнт відношення висоти до довжини (зазвичай $ \\beta = 8/3 $).\n",
        "\n",
        "#### **Об'єкти Нарендра-Пархтізаратхі:**\n",
        "\n",
        "Об'єкти Нарендра-Пархтізаратхі описуються наступними рівняннями:\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "x_1(t+1) = \\alpha_1 x_1(t) + \\beta_1 x_2(t) + \\gamma_1 x_3(t) + \\delta_1 \\\\\n",
        "x_2(t+1) = \\alpha_2 x_1(t) + \\beta_2 x_2(t) + \\gamma_2 x_3(t) + \\delta_2 \\\\\n",
        "x_3(t+1) = \\alpha_3 x_1(t) + \\beta_3 x_2(t) + \\gamma_3 x_3(t) + \\delta_3\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "де $(\\alpha_i)$, $(\\beta_i)$, $(\\gamma_i)$ і $(\\delta_i)$ — коефіцієнти для кожного з рівнянь.\n",
        "\n",
        "#### **Завдання до лабораторної роботи:**\n",
        "\n",
        "Завдання 1. *Генерація даних:*\n",
        "\n",
        "   1.1 Згенеруйте дані для системи Лоренца з використанням зазначених параметрів. Виробіть не менше ніж 10 000 точок даних.\n",
        "\n",
        "   1.2 Згенеруйте дані для об'єктів Нарендра-Пархтізаратхі, використовуючи різні значення коефіцієнтів $(\\alpha_i)$, $(\\beta_i)$, $(\\gamma_i)$ і $(\\delta_i)$. Виробіть не менше ніж 10 000 точок даних.\n",
        "\n",
        "---\n",
        "Завдання 2. *Підготовка даних:*\n",
        "   \n",
        "   2.1 Розділіть дані на навчальний, валідаційний і тестовий набори. Використовуйте 70% для навчання, 15% для валідації та 15% для тестування.\n",
        "   \n",
        "   2.2 Нормалізуйте дані за допомогою StandardScaler. Убедитесь, що всі дані масштабовані перед навчанням моделей.\n",
        "\n",
        "---\n",
        "Завдання 3. *Моделювання:*\n",
        "   \n",
        "   3.1 Застосуйте наступні моделі машинного навчання:\n",
        "     \n",
        "     - Лінійна регресія\n",
        "     - Дерево рішень\n",
        "     - Случайний ліс (Random Forest)\n",
        "     - Метод опорних векторів (SVM)\n",
        "   \n",
        "   3.2 Для кожної моделі виконайте тренування на навчальному наборі даних.\n",
        "\n",
        "---\n",
        "Завдання 4. *Підбір гіперпараметрів:*\n",
        "   \n",
        "   4.1 Для кожної моделі використовуйте Grid Search для підбору оптимальних гіперпараметрів. Параметри для підбору:\n",
        "     \n",
        "     - Лінійна регресія: (не потребує підбору гіперпараметрів, але перевірте регуляризацію)\n",
        "     - Дерево рішень: `max_depth`, `min_samples_split`, `min_samples_leaf`\n",
        "     - Випадковий ліс: `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`\n",
        "     - SVM: `C`, `kernel`, `gamma`\n",
        "---\n",
        "Завдання 5. *Оцінка моделей:*\n",
        "   \n",
        "   5.1 Оцініть кожну модель на валідаційному наборі за допомогою середньої квадратичної помилки (MSE) та R².\n",
        "  \n",
        "   5.2 Виконайте фінальну оцінку на тестовому наборі даних.\n",
        "\n",
        "---\n",
        "Завдання 6. *Аналіз результатів:*\n",
        "   \n",
        "   6.1 Порівняйте результати всіх моделей. Створіть таблицю з метриками для кожної моделі.\n",
        "\n",
        "   6.2 Візуалізуйте результати прогнозування для кожної моделі (наприклад, графіки реальних значень проти прогнозованих).\n",
        "\n",
        "---\n",
        "Завдання 7. *Документація та звіт:*\n",
        "   \n",
        "   7.1 Опишіть методику генерації даних, моделювання, підбору гіперпараметрів та оцінки моделей.\n",
        "   \n",
        "   7.2 Підготуйте звіт з результатами, включаючи таблиці, графіки та висновки про найкращу модель.\n",
        "\n",
        "---\n",
        "#### **Інструкції:**\n",
        "\n",
        "1. **Генерація даних:**\n",
        "   Використовуйте бібліотеки `numpy` та `scipy` для генерації даних.\n",
        "\n",
        "2. **Навчання моделей:**\n",
        "   Використовуйте `scikit-learn` для реалізації моделей і налаштування гіперпараметрів.\n",
        "\n",
        "3. **Оцінка моделей:**\n",
        "   Використовуйте функції `mean_squared_error`, `r2_score` з `sklearn.metrics` для оцінки.\n",
        "\n",
        "4. **Візуалізація:**\n",
        "   Для візуалізації використовуйте бібліотеки `matplotlib` та `seaborn`.\n",
        "\n",
        "5. **Документація:**\n",
        "   Оформіть звіт у форматі Jupyter Notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4nYbsVCg6Cl"
      },
      "source": [
        "## **Додаткова умова до лабораторної роботи 5:**\n",
        "\n",
        "*Для того, щоб отримати оцінку більше 50 балів, Вам необхідно використати якесь з цих рівнянь. Вибір рівняння вібдувається відповідно до Вашого номеру в журналі групи.*\n",
        "\n",
        "\n",
        "**Об'єкти Нарендра-Партхізаратхі (Narendra-Parthasarathy)** — це нелінійні системи управління, які часто використовуються для тестування адаптивних і нелінійних регуляторів. Їх поведінка моделюється нелінійними диференціальними рівняннями, що описують динаміку в часі. Ці рівняння створюють цікаву, нелінійну та хаотичну поведінку системи.\n",
        "\n",
        "### **Нелінійних рівнянь Нарендра-Партхізаратхі:**\n",
        "\n",
        "1. $$\n",
        "\\dot{x}_1 = -a_1 x_1 + b_1 x_2^2\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = -a_2 x_2 + b_2 \\sin(x_1)\n",
        "$$\n",
        "\n",
        "2. $$\n",
        "\\dot{x}_1 = a_1 \\sin(x_2) - b_1 x_1^2\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 x_1 x_2 - b_2 \\cos(x_1)\n",
        "$$\n",
        "\n",
        "3. $$\n",
        "\\dot{x}_1 = -a_1 x_1 + b_1 x_2^3\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 \\sin(x_1) - b_2 x_2\n",
        "$$\n",
        "\n",
        "4. $$\n",
        "\\dot{x}_1 = a_1 x_1 - b_1 x_2 \\sin(x_1)\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = -a_2 x_2 + b_2 \\cos(x_1)\n",
        "$$\n",
        "\n",
        "5. $$\n",
        "\\dot{x}_1 = -a_1 x_1 + b_1 x_2^2 \\cos(x_1)\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 \\sin(x_1) - b_2 x_1 x_2\n",
        "$$\n",
        "\n",
        "6. $$\n",
        "\\dot{x}_1 = a_1 x_1 x_2 - b_1 x_1^3\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 \\sin(x_1) - b_2 x_2^2\n",
        "$$\n",
        "\n",
        "7. $$\n",
        "\\dot{x}_1 = -a_1 x_1^2 + b_1 \\cos(x_2)\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 x_1 - b_2 \\sin(x_2)\n",
        "$$\n",
        "\n",
        "8. $$\n",
        "\\dot{x}_1 = a_1 \\sin(x_2) - b_1 x_1^2\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = -a_2 x_2 + b_2 x_1 \\cos(x_2)\n",
        "$$\n",
        "\n",
        "9. $$\n",
        "\\dot{x}_1 = a_1 x_1^2 - b_1 x_2^2\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 \\cos(x_1) - b_2 \\sin(x_2)\n",
        "$$\n",
        "\n",
        "10. $$\n",
        "\\dot{x}_1 = -a_1 x_1 \\sin(x_2) + b_1 x_2^3\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 \\cos(x_1) - b_2 x_1 x_2\n",
        "$$\n",
        "\n",
        "11. $$\n",
        "\\dot{x}_1 = a_1 \\sin(x_1 x_2) - b_1 x_1\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = -a_2 x_2^2 + b_2 \\cos(x_1)\n",
        "$$\n",
        "\n",
        "12. $$\n",
        "\\dot{x}_1 = -a_1 x_1 + b_1 \\sin(x_2^2)\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 x_1^2 - b_2 \\cos(x_1)\n",
        "$$\n",
        "\n",
        "13. $$\n",
        "\\dot{x}_1 = a_1 x_1 x_2 - b_1 \\sin(x_1^2)\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = -a_2 x_2 + b_2 \\cos(x_1 x_2)\n",
        "$$\n",
        "\n",
        "14. $$\n",
        "\\dot{x}_1 = a_1 x_1 - b_1 x_2^2 \\sin(x_1)\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 \\cos(x_1) - b_2 x_1^3\n",
        "$$\n",
        "\n",
        "15. $$\n",
        "\\dot{x}_1 = a_1 \\cos(x_2) - b_1 x_1^2 \\sin(x_1)\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = -a_2 x_1 x_2 + b_2 \\cos(x_1^2)\n",
        "$$\n",
        "\n",
        "16. $$\n",
        "\\dot{x}_1 = -a_1 \\sin(x_1) + b_1 x_2^2\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 \\sin(x_1 x_2) - b_2 \\cos(x_1)\n",
        "$$\n",
        "\n",
        "17. $$\n",
        "\\dot{x}_1 = a_1 x_1^2 \\cos(x_2) - b_1 x_1 x_2\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = -a_2 x_2 + b_2 \\sin(x_1^2)\n",
        "$$\n",
        "\n",
        "18. $$\n",
        "\\dot{x}_1 = -a_1 x_1 \\sin(x_2) + b_1 \\cos(x_1^2)\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 x_1^2 - b_2 \\cos(x_1 x_2)\n",
        "$$\n",
        "\n",
        "19. $$\n",
        "\\dot{x}_1 = a_1 \\sin(x_2) - b_1 x_1^2\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 \\cos(x_1) - b_2 x_2^2\n",
        "$$\n",
        "\n",
        "20. $$\n",
        "\\dot{x}_1 = -a_1 x_1^2 + b_1 \\sin(x_1 x_2)\n",
        "$$\n",
        "$$\n",
        "\\dot{x}_2 = a_2 \\cos(x_1) - b_2 \\sin(x_2^2)\n",
        "$$\n",
        "\n",
        "### Параметри:\n",
        "- $( a_1, a_2 )$, $( b_1, b_2 )$ — це коефіцієнти, які можуть бути варійовані для дослідження динаміки системи та впливу на прогнозування."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eZ_jQFiqHjwp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ouS8zTbVNbrh"
      },
      "outputs": [],
      "source": [
        "# №1\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.integrate import odeint\n",
        "\n",
        "# 1.1\n",
        "def lorenz_system(state, t, sigma, rho, beta):\n",
        "    x, y, z = state\n",
        "    dxdt = sigma * (y - x)\n",
        "    dydt = x * (rho - z) - y\n",
        "    dzdt = x * y - beta * z\n",
        "    return dxdt, dydt, dzdt\n",
        "\n",
        "sigma = 10\n",
        "rho = 28\n",
        "beta = 8/3\n",
        "initial_state = [0., 1., 1.05]\n",
        "t = np.linspace(0, 100, 10000)\n",
        "lorenz_data = odeint(lorenz_system, initial_state, t, args=(sigma, rho, beta))\n",
        "\n",
        "# 1.2\n",
        "def narendra_parthasarathy(t, alpha, beta, gamma, delta, x0, x1, x2):\n",
        "    x = np.zeros((len(t), 3))\n",
        "    x[0] = [x0, x1, x2]\n",
        "    for i in range(1, len(t)):\n",
        "        x[i, 0] = alpha[0] * x[i-1, 0] + beta[0] * x[i-1, 1] + gamma[0] * x[i-1, 2] + delta[0]\n",
        "        x[i, 1] = alpha[1] * x[i-1, 0] + beta[1] * x[i-1, 1] + gamma[1] * x[i-1, 2] + delta[1]\n",
        "        x[i, 2] = alpha[2] * x[i-1, 0] + beta[2] * x[i-1, 1] + gamma[2] * x[i-1, 2] + delta[2]\n",
        "    return x\n",
        "\n",
        "alpha = [0.1, 0.1, 0.1]\n",
        "beta = [0.1, 0.1, 0.1]\n",
        "gamma = [0.1, 0.1, 0.1]\n",
        "delta = [0, 0, 0]\n",
        "narendra_data = narendra_parthasarathy(t, alpha, beta, gamma, delta, 0., 1., 1.05)\n",
        "\n",
        "data = np.hstack((lorenz_data, narendra_data))\n",
        "df = pd.DataFrame(data, columns=['x_lorenz', 'y_lorenz', 'z_lorenz', 'x_narendra', 'y_narendra', 'z_narendra'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "82VC6GNgNjiu"
      },
      "outputs": [],
      "source": [
        "# №2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 2.1\n",
        "X = df[['x_lorenz', 'y_lorenz', 'z_lorenz']]\n",
        "y = df[['x_narendra', 'y_narendra', 'z_narendra']]\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# 2.2\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ymd0pctkNlRX"
      },
      "outputs": [],
      "source": [
        "# №3\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Support Vector Machine': SVR()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    mse = mean_squared_error(y_val, y_val_pred)\n",
        "    r2 = r2_score(y_val, y_val_pred)\n",
        "    print(f\"{name} - MSE: {mse:.4f}, R²: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zqk_-odlNmAe"
      },
      "outputs": [],
      "source": [
        "# №4\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'Decision Tree': {\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2]\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [10, 50],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2]\n",
        "    },\n",
        "    'Support Vector Machine': {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 'auto']\n",
        "    }\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name in param_grid:\n",
        "        grid_search = GridSearchCV(model, param_grid[name], cv=3)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        print(f\"{name} Best parameters: {grid_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Tx8hInVMNmo7"
      },
      "outputs": [],
      "source": [
        "# №5\n",
        "for name, model in models.items():\n",
        "    if name in param_grid:\n",
        "        model.fit(X_train, y_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_test_pred)\n",
        "    r2 = r2_score(y_test, y_test_pred)\n",
        "    print(f\"{name} (Test) - MSE: {mse:.4f}, R²: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT5yLyrgNnRv"
      },
      "outputs": [],
      "source": [
        "# №6\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "results = pd.DataFrame(columns=['Model', 'MSE', 'R²'])\n",
        "for name in models.keys():\n",
        "    y_test_pred = models[name].predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_test_pred)\n",
        "    r2 = r2_score(y_test, y_test_pred)\n",
        "    results = results.append({'Model': name, 'MSE': mse, 'R²': r2}, ignore_index=True)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='MSE', data=results)\n",
        "plt.title('MSE for Each Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# №7\n",
        "report = \"\"\"\n",
        "## Report on Laboratory Work 4\n",
        "\n",
        "### Data Generation Methodology\n",
        "- The Lorenz system was modeled using differential equations.\n",
        "- Narendra-Parthasarathy objects were modeled using linear equations.\n",
        "\n",
        "### Modeling\n",
        "- Four machine learning models were used: Linear Regression, Decision Tree, Random Forest, and Support Vector Machine.\n",
        "\n",
        "### Hyperparameter Tuning\n",
        "- Hyperparameters were tuned for each model using Grid Search.\n",
        "\n",
        "### Model Evaluation\n",
        "- Models were evaluated on test data using MSE and R² metrics.\n",
        "\"\"\"\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
